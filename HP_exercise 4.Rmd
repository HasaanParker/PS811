---
title: 'Exercise 5: Base R vs. Tidyverse'
author: "Dillon Laaker"
date: "10/15/2020"
output: pdf_document
---

```{r setup, include=FALSE}
library(tidyverse)
```


# Base R tasks

1. Download the food_coded.csv file


2. Load the CSV file into your R environment.
```{r}
food <- read.csv("food_coded.csv")
```

    Open the `codebook_food.docx` file for guidance.

3. Extract the first 95 rows.
```{r}
food_2 <- food[1:95,]
```


4. Look at the following variables using both name and column index/number.

    * GPA
    * calories_chicken
    * drink
    * fav_cuisine
    * father_profession
    * mother_profession
```{r}
food_3 <- food[, c("GPA", "calories_chicken", "drink", "fav_cuisine", "father_profession", "mother_profession")]
food_4 <- food[, c(1, 4, 16, 26, 25, 45)]
```


5. Create a new variable for how healthy each person feels but convert the scale from 1 to 10 to 1 to 100.
```{r}
food_5 <- food
food_5$health <- food_5$healthy_feeling * 10
```

6. Filter to students who are female and have GPAs that are above 3.0.
```{r}
food_6 <- food[food$Gender == 1 & food$GPA > 3, ]

```

7. Find the mean and standard deviation for the following variables, and summarize them in a data frame.
```{r}
food_7 <- food[, c("calories_chicken", "tortilla_calories", "turkey_calories", "waffle_calories" )]

cal_means <- sapply(food_7, mean, na.rm = T)
cal_sd <- sapply(food_7, sd, na.rm = T)
cal_summary <- rbind(cal_means, cal_sd)
rownames(cal_summary) <- c("Mean calories", "SD of calories")
cal_summary
```

    * chicken_calories
    * tortilla_calories
    * turkey_calories
    * waffle_calories
    
8. Summarize GPA and weight within the gender and cuisine variables.
```{r}
food$GPA <- as.numeric(food$GPA)
food$weight <- as.numeric(food$weight)
food$GPA[74] <- 3.79
food$weight[4] <- 240
food$weight[68] <- 144
food_men <- food[food$Gender == 1,]
food_women <- food[food$Gender ==2, ]
men_GPA_mean <- tapply(food_men$GPA, food_men$cuisine, mean, na.rm = T)
women_GPA_mean <- tapply(food_women$GPA, food_women$cuisine, mean, na.rm = T)
men_weight_mean <- tapply(food_men$weight, food_men$cuisine, mean, na.rm = T)
women_weight_mean <- tapply(food_women$weight, food_women$cuisine, mean, na.rm = T)

men_GPA_sd <- tapply(food_men$GPA, food_men$cuisine, sd, na.rm = T)
women_GPA_sd <- tapply(food_women$GPA, food_women$cuisine, sd, na.rm = T)
men_weight_sd <- tapply(food_men$weight, food_men$cuisine, sd, na.rm = T)
women_weight_sd <- tapply(food_women$weight, food_women$cuisine, sd, na.rm = T)

men_summary <- rbind(men_GPA_mean, men_GPA_sd, men_weight_mean, men_weight_sd)
men_summary <- cbind(men_summary, rep(0, length(men_summary[,1])))

rbind(women_GPA_mean, women_GPA_sd, women_weight_mean, women_weight_sd)
```


# Tidyverse tasks

1. Download the facebook-fact-check.csv

2. Load the CSV file into your R environment.
```{r}
fb_data <- read_csv("facebook-fact-check.csv")
```


3. Extract the last 500 rows.

    Hint: Check out the [top_n() page](https://rdrr.io/github/YTLogos/dplyr/man/top_n.html) to figure out how to extract the last 500 rows instead of the first 500 rows.
```{r}
fb_data %>% slice_tail(n = 500)
```
  
4. Look at the even-numbered column indices only. Identify them by name.
```{r}
fb_data %>% select(seq(from = 0, to = ncol(fb_data), by = 2)) %>% colnames()
```

5. Using `mutate`, create a new variable called `post_type_coded` that renames each post type to the following:

    * link = 1
    * photo = 2
    * text = 3
    * video = 4
    
    Hint: look up case_when within tidyverse. You can also use if_else
```{r}
fb_data <- fb_data %>% 
    mutate(post_type_coded = case_when(
        `Post Type` == "link" ~ 1,
        `Post Type` == "photo" ~ 2,
        `Post Type` == "text" ~ 3,
        `Post Type` == "video" ~ 4
    ))
```
    
6. Arrange page names in reverse order.
```{r}
fb_data %>% arrange(desc(Page)) 
```

7. Find the mean and standard deviation for the following variables, and summarize them.

    * share_count
    * reaction_count
    * comment_count
```{r}
fb_data %>% 
    summarise(across(c(share_count, reaction_count, comment_count), list(mean = mean, sd = sd), na.rm = TRUE))

fb_data %>% 
    group_by(Page) %>% 
    summarise(Mean_Share_Count = mean(share_count, na.rm=T),
              SD_Share_count = sd(share_count, na.rm = T))
    

```

8. Summarize the mean and standard deviations in Question 7 with the "mainstream" values in the `category` variable.
```{r}
fb_data %>% 
    filter(Category == "mainstream") %>% 
    summarise(across(c(share_count, reaction_count, comment_count), list(mean = mean, sd = sd), na.rm = TRUE))
```

# Submit

Email me (laaker@wisc.edu) the link to your `ps811-exercises` repository when you are done.